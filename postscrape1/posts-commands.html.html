<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Command line tool &mdash; Scrapy 2.6.1 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/tooltipster.custom.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/tooltipster.bundle.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/tooltipster-sideTip-shadow.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/tooltipster-sideTip-punk.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/tooltipster-sideTip-noir.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/tooltipster-sideTip-light.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/tooltipster-sideTip-borderless.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/micromodal.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/sphinx_rtd_theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="canonical" href="https://docs.scrapy.org/en/latest/topics/commands.html" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/js/hoverxref.js"></script>
        <script src="../_static/js/tooltipster.bundle.min.js"></script>
        <script src="../_static/js/micromodal.min.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script async="async" src="/_/static/javascript/readthedocs-doc-embed.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Spiders" href="spiders.html" />
    <link rel="prev" title="Examples" href="../intro/examples.html" /> 

<!-- RTD Extra Head -->

<link rel="stylesheet" href="/_/static/css/readthedocs-doc-embed.css" type="text/css" />

<script type="application/json" id="READTHEDOCS_DATA">{"ad_free": false, "api_host": "https://readthedocs.org", "build_date": "2022-05-26T14:18:52Z", "builder": "sphinx", "canonical_url": null, "commit": "23537a0f", "docroot": "/docs/", "features": {"docsearch_disabled": false}, "global_analytics_code": "UA-17997319-1", "language": "en", "page": "topics/commands", "programming_language": "py", "project": "scrapy", "proxied_api_host": "/_", "source_suffix": ".rst", "subprojects": {}, "theme": "sphinx_rtd_theme", "user_analytics_code": "UA-10231918-2", "version": "latest"}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type="text/javascript">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type="text/javascript" src="/_/static/javascript/readthedocs-analytics.js" async="async"></script>

<!-- end RTD <extrahead> -->
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> Scrapy
          </a>
              <div class="version">
                latest
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">First steps</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intro/overview.html">Scrapy at a glance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/install.html">Installation guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/tutorial.html">Scrapy Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/examples.html">Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic concepts</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Command line tool</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#configuration-settings">Configuration settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="#default-structure-of-scrapy-projects">Default structure of Scrapy projects</a></li>
<li class="toctree-l2"><a class="reference internal" href="#sharing-the-root-directory-between-projects">Sharing the root directory between projects</a></li>
<li class="toctree-l2"><a class="reference internal" href="#using-the-scrapy-tool">Using the <code class="docutils literal notranslate"><span class="pre">scrapy</span></code> tool</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#creating-projects">Creating projects</a></li>
<li class="toctree-l3"><a class="reference internal" href="#controlling-projects">Controlling projects</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#available-tool-commands">Available tool commands</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#startproject">startproject</a></li>
<li class="toctree-l3"><a class="reference internal" href="#genspider">genspider</a></li>
<li class="toctree-l3"><a class="reference internal" href="#crawl">crawl</a></li>
<li class="toctree-l3"><a class="reference internal" href="#check">check</a></li>
<li class="toctree-l3"><a class="reference internal" href="#list">list</a></li>
<li class="toctree-l3"><a class="reference internal" href="#edit">edit</a></li>
<li class="toctree-l3"><a class="reference internal" href="#fetch">fetch</a></li>
<li class="toctree-l3"><a class="reference internal" href="#view">view</a></li>
<li class="toctree-l3"><a class="reference internal" href="#shell">shell</a></li>
<li class="toctree-l3"><a class="reference internal" href="#parse">parse</a></li>
<li class="toctree-l3"><a class="reference internal" href="#settings">settings</a></li>
<li class="toctree-l3"><a class="reference internal" href="#runspider">runspider</a></li>
<li class="toctree-l3"><a class="reference internal" href="#version">version</a></li>
<li class="toctree-l3"><a class="reference internal" href="#bench">bench</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#custom-project-commands">Custom project commands</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#commands-module">COMMANDS_MODULE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#register-commands-via-setup-py-entry-points">Register commands via setup.py entry points</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="spiders.html">Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="selectors.html">Selectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="items.html">Items</a></li>
<li class="toctree-l1"><a class="reference internal" href="loaders.html">Item Loaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="shell.html">Scrapy shell</a></li>
<li class="toctree-l1"><a class="reference internal" href="item-pipeline.html">Item Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="feed-exports.html">Feed exports</a></li>
<li class="toctree-l1"><a class="reference internal" href="request-response.html">Requests and Responses</a></li>
<li class="toctree-l1"><a class="reference internal" href="link-extractors.html">Link Extractors</a></li>
<li class="toctree-l1"><a class="reference internal" href="settings.html">Settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="exceptions.html">Exceptions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Built-in services</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="stats.html">Stats Collection</a></li>
<li class="toctree-l1"><a class="reference internal" href="email.html">Sending e-mail</a></li>
<li class="toctree-l1"><a class="reference internal" href="telnetconsole.html">Telnet Console</a></li>
<li class="toctree-l1"><a class="reference internal" href="webservice.html">Web Service</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Solving specific problems</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="debug.html">Debugging Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="contracts.html">Spiders Contracts</a></li>
<li class="toctree-l1"><a class="reference internal" href="practices.html">Common Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="broad-crawls.html">Broad Crawls</a></li>
<li class="toctree-l1"><a class="reference internal" href="developer-tools.html">Using your browser’s Developer Tools for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="dynamic-content.html">Selecting dynamically-loaded content</a></li>
<li class="toctree-l1"><a class="reference internal" href="leaks.html">Debugging memory leaks</a></li>
<li class="toctree-l1"><a class="reference internal" href="media-pipeline.html">Downloading and processing files and images</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy.html">Deploying Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="autothrottle.html">AutoThrottle extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="jobs.html">Jobs: pausing and resuming crawls</a></li>
<li class="toctree-l1"><a class="reference internal" href="coroutines.html">Coroutines</a></li>
<li class="toctree-l1"><a class="reference internal" href="asyncio.html">asyncio</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Extending Scrapy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Architecture overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="downloader-middleware.html">Downloader Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="spider-middleware.html">Spider Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="extensions.html">Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">Core API</a></li>
<li class="toctree-l1"><a class="reference internal" href="signals.html">Signals</a></li>
<li class="toctree-l1"><a class="reference internal" href="scheduler.html">Scheduler</a></li>
<li class="toctree-l1"><a class="reference internal" href="exporters.html">Item Exporters</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">All the rest</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">Release notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to Scrapy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../versioning.html">Versioning and API stability</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Scrapy</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Command line tool</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/scrapy/scrapy/blob/2.6.1/docs/topics/commands.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="command-line-tool">
<span id="topics-commands"></span><h1>Command line tool<a class="headerlink" href="#command-line-tool" title="Permalink to this headline">¶</a></h1>
<p>Scrapy is controlled through the <code class="docutils literal notranslate"><span class="pre">scrapy</span></code> command-line tool, to be referred
here as the “Scrapy tool” to differentiate it from the sub-commands, which we
just call “commands” or “Scrapy commands”.</p>
<p>The Scrapy tool provides several commands, for multiple purposes, and each one
accepts a different set of arguments and options.</p>
<p>(The <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">deploy</span></code> command has been removed in 1.0 in favor of the
standalone <code class="docutils literal notranslate"><span class="pre">scrapyd-deploy</span></code>. See <a class="reference external" href="https://scrapyd.readthedocs.io/en/latest/deploy.html">Deploying your project</a>.)</p>
<section id="configuration-settings">
<span id="topics-config-settings"></span><h2>Configuration settings<a class="headerlink" href="#configuration-settings" title="Permalink to this headline">¶</a></h2>
<p>Scrapy will look for configuration parameters in ini-style <code class="docutils literal notranslate"><span class="pre">scrapy.cfg</span></code> files
in standard locations:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">/etc/scrapy.cfg</span></code> or <code class="docutils literal notranslate"><span class="pre">c:\scrapy\scrapy.cfg</span></code> (system-wide),</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">~/.config/scrapy.cfg</span></code> (<code class="docutils literal notranslate"><span class="pre">$XDG_CONFIG_HOME</span></code>) and <code class="docutils literal notranslate"><span class="pre">~/.scrapy.cfg</span></code> (<code class="docutils literal notranslate"><span class="pre">$HOME</span></code>)
for global (user-wide) settings, and</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scrapy.cfg</span></code> inside a Scrapy project’s root (see next section).</p></li>
</ol>
<p>Settings from these files are merged in the listed order of preference:
user-defined values have higher priority than system-wide defaults
and project-wide settings will override all others, when defined.</p>
<p>Scrapy also understands, and can be configured through, a number of environment
variables. Currently these are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">SCRAPY_SETTINGS_MODULE</span></code> (see <a class="hoverxref tooltip reference internal" href="settings.html#topics-settings-module-envvar"><span class="std std-ref">Designating the settings</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SCRAPY_PROJECT</span></code> (see <a class="hoverxref tooltip reference internal" href="#topics-project-envvar"><span class="std std-ref">Sharing the root directory between projects</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SCRAPY_PYTHON_SHELL</span></code> (see <a class="hoverxref tooltip reference internal" href="shell.html#topics-shell"><span class="std std-ref">Scrapy shell</span></a>)</p></li>
</ul>
</section>
<section id="default-structure-of-scrapy-projects">
<span id="topics-project-structure"></span><h2>Default structure of Scrapy projects<a class="headerlink" href="#default-structure-of-scrapy-projects" title="Permalink to this headline">¶</a></h2>
<p>Before delving into the command-line tool and its sub-commands, let’s first
understand the directory structure of a Scrapy project.</p>
<p>Though it can be modified, all Scrapy projects have the same file
structure by default, similar to this:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>scrapy.cfg
myproject/
    __init__.py
    items.py
    middlewares.py
    pipelines.py
    settings.py
    spiders/
        __init__.py
        spider1.py
        spider2.py
        ...
</pre></div>
</div>
<p>The directory where the <code class="docutils literal notranslate"><span class="pre">scrapy.cfg</span></code> file resides is known as the <em>project
root directory</em>. That file contains the name of the python module that defines
the project settings. Here is an example:</p>
<div class="highlight-ini notranslate"><div class="highlight"><pre><span></span><span class="k">[settings]</span><span class="w"></span>
<span class="na">default</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">myproject.settings</span><span class="w"></span>
</pre></div>
</div>
</section>
<section id="sharing-the-root-directory-between-projects">
<span id="topics-project-envvar"></span><h2>Sharing the root directory between projects<a class="headerlink" href="#sharing-the-root-directory-between-projects" title="Permalink to this headline">¶</a></h2>
<p>A project root directory, the one that contains the <code class="docutils literal notranslate"><span class="pre">scrapy.cfg</span></code>, may be
shared by multiple Scrapy projects, each with its own settings module.</p>
<p>In that case, you must define one or more aliases for those settings modules
under <code class="docutils literal notranslate"><span class="pre">[settings]</span></code> in your <code class="docutils literal notranslate"><span class="pre">scrapy.cfg</span></code> file:</p>
<div class="highlight-ini notranslate"><div class="highlight"><pre><span></span><span class="k">[settings]</span><span class="w"></span>
<span class="na">default</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">myproject1.settings</span><span class="w"></span>
<span class="na">project1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">myproject1.settings</span><span class="w"></span>
<span class="na">project2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">myproject2.settings</span><span class="w"></span>
</pre></div>
</div>
<p>By default, the <code class="docutils literal notranslate"><span class="pre">scrapy</span></code> command-line tool will use the <code class="docutils literal notranslate"><span class="pre">default</span></code> settings.
Use the <code class="docutils literal notranslate"><span class="pre">SCRAPY_PROJECT</span></code> environment variable to specify a different project
for <code class="docutils literal notranslate"><span class="pre">scrapy</span></code> to use:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$ scrapy settings --get BOT_NAME
Project 1 Bot
$ export SCRAPY_PROJECT=project2
$ scrapy settings --get BOT_NAME
Project 2 Bot
</pre></div>
</div>
</section>
<section id="using-the-scrapy-tool">
<h2>Using the <code class="docutils literal notranslate"><span class="pre">scrapy</span></code> tool<a class="headerlink" href="#using-the-scrapy-tool" title="Permalink to this headline">¶</a></h2>
<p>You can start by running the Scrapy tool with no arguments and it will print
some usage help and the available commands:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Scrapy X.Y - no active project

Usage:
  scrapy &lt;command&gt; [options] [args]

Available commands:
  crawl         Run a spider
  fetch         Fetch a URL using the Scrapy downloader
[...]
</pre></div>
</div>
<p>The first line will print the currently active project if you’re inside a
Scrapy project. In this example it was run from outside a project. If run from inside
a project it would have printed something like this:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Scrapy X.Y - project: myproject

Usage:
  scrapy &lt;command&gt; [options] [args]

[...]
</pre></div>
</div>
<section id="creating-projects">
<h3>Creating projects<a class="headerlink" href="#creating-projects" title="Permalink to this headline">¶</a></h3>
<p>The first thing you typically do with the <code class="docutils literal notranslate"><span class="pre">scrapy</span></code> tool is create your Scrapy
project:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>scrapy startproject myproject [project_dir]
</pre></div>
</div>
<p>That will create a Scrapy project under the <code class="docutils literal notranslate"><span class="pre">project_dir</span></code> directory.
If <code class="docutils literal notranslate"><span class="pre">project_dir</span></code> wasn’t specified, <code class="docutils literal notranslate"><span class="pre">project_dir</span></code> will be the same as <code class="docutils literal notranslate"><span class="pre">myproject</span></code>.</p>
<p>Next, you go inside the new project directory:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>cd project_dir
</pre></div>
</div>
<p>And you’re ready to use the <code class="docutils literal notranslate"><span class="pre">scrapy</span></code> command to manage and control your
project from there.</p>
</section>
<section id="controlling-projects">
<h3>Controlling projects<a class="headerlink" href="#controlling-projects" title="Permalink to this headline">¶</a></h3>
<p>You use the <code class="docutils literal notranslate"><span class="pre">scrapy</span></code> tool from inside your projects to control and manage
them.</p>
<p>For example, to create a new spider:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>scrapy genspider mydomain mydomain.com
</pre></div>
</div>
<p>Some Scrapy commands (like <a class="hoverxref tooltip reference internal" href="#std-command-crawl"><code class="xref std std-command docutils literal notranslate"><span class="pre">crawl</span></code></a>) must be run from inside a Scrapy
project. See the <a class="hoverxref tooltip reference internal" href="#topics-commands-ref"><span class="std std-ref">commands reference</span></a> below for more
information on which commands must be run from inside projects, and which not.</p>
<p>Also keep in mind that some commands may have slightly different behaviours
when running them from inside projects. For example, the fetch command will use
spider-overridden behaviours (such as the <code class="docutils literal notranslate"><span class="pre">user_agent</span></code> attribute to override
the user-agent) if the url being fetched is associated with some specific
spider. This is intentional, as the <code class="docutils literal notranslate"><span class="pre">fetch</span></code> command is meant to be used to
check how spiders are downloading pages.</p>
</section>
</section>
<section id="available-tool-commands">
<span id="topics-commands-ref"></span><h2>Available tool commands<a class="headerlink" href="#available-tool-commands" title="Permalink to this headline">¶</a></h2>
<p>This section contains a list of the available built-in commands with a
description and some usage examples. Remember, you can always get more info
about each command by running:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>scrapy &lt;command&gt; -h
</pre></div>
</div>
<p>And you can see all available commands with:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>scrapy -h
</pre></div>
</div>
<p>There are two kinds of commands, those that only work from inside a Scrapy
project (Project-specific commands) and those that also work without an active
Scrapy project (Global commands), though they may behave slightly different
when running from inside a project (as they would use the project overridden
settings).</p>
<p>Global commands:</p>
<ul class="simple">
<li><p><a class="hoverxref tooltip reference internal" href="#std-command-startproject"><code class="xref std std-command docutils literal notranslate"><span class="pre">startproject</span></code></a></p></li>
<li><p><a class="hoverxref tooltip reference internal" href="#std-command-genspider"><code class="xref std std-command docutils literal notranslate"><span class="pre">genspider</span></code></a></p></li>
<li><p><a class="hoverxref tooltip reference internal" href="#std-command-settings"><code class="xref std std-command docutils literal notranslate"><span class="pre">settings</span></code></a></p></li>
<li><p><a class="hoverxref tooltip reference internal" href="#std-command-runspider"><code class="xref std std-command docutils literal notranslate"><span class="pre">runspider</span></code></a></p></li>
<li><p><a class="hoverxref tooltip reference internal" href="#std-command-shell"><code class="xref std std-command docutils literal notranslate"><span class="pre">shell</span></code></a></p></li>
<li><p><a class="hoverxref tooltip reference internal" href="#std-command-fetch"><code class="xref std std-command docutils literal notranslate"><span class="pre">fetch</span></code></a></p></li>
<li><p><a class="hoverxref tooltip reference internal" href="#std-command-view"><code class="xref std std-command docutils literal notranslate"><span class="pre">view</span></code></a></p></li>
<li><p><a class="hoverxref tooltip reference internal" href="#std-command-version"><code class="xref std std-command docutils literal notranslate"><span class="pre">version</span></code></a></p></li>
</ul>
<p>Project-only commands:</p>
<ul class="simple">
<li><p><a class="hoverxref tooltip reference internal" href="#std-command-crawl"><code class="xref std std-command docutils literal notranslate"><span class="pre">crawl</span></code></a></p></li>
<li><p><a class="hoverxref tooltip reference internal" href="#std-command-check"><code class="xref std std-command docutils literal notranslate"><span class="pre">check</span></code></a></p></li>
<li><p><a class="hoverxref tooltip reference internal" href="#std-command-list"><code class="xref std std-command docutils literal notranslate"><span class="pre">list</span></code></a></p></li>
<li><p><a class="hoverxref tooltip reference internal" href="#std-command-edit"><code class="xref std std-command docutils literal notranslate"><span class="pre">edit</span></code></a></p></li>
<li><p><a class="hoverxref tooltip reference internal" href="#std-command-parse"><code class="xref std std-command docutils literal notranslate"><span class="pre">parse</span></code></a></p></li>
<li><p><a class="hoverxref tooltip reference internal" href="#std-command-bench"><code class="xref std std-command docutils literal notranslate"><span class="pre">bench</span></code></a></p></li>
</ul>
<section id="startproject">
<span id="std-command-startproject"></span><span id="std:command-startproject"></span><h3>startproject<a class="headerlink" href="#startproject" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">startproject</span> <span class="pre">&lt;project_name&gt;</span> <span class="pre">[project_dir]</span></code></p></li>
<li><p>Requires project: <em>no</em></p></li>
</ul>
<p>Creates a new Scrapy project named <code class="docutils literal notranslate"><span class="pre">project_name</span></code>, under the <code class="docutils literal notranslate"><span class="pre">project_dir</span></code>
directory.
If <code class="docutils literal notranslate"><span class="pre">project_dir</span></code> wasn’t specified, <code class="docutils literal notranslate"><span class="pre">project_dir</span></code> will be the same as <code class="docutils literal notranslate"><span class="pre">project_name</span></code>.</p>
<p>Usage example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$ scrapy startproject myproject
</pre></div>
</div>
</section>
<section id="genspider">
<span id="std-command-genspider"></span><span id="std:command-genspider"></span><h3>genspider<a class="headerlink" href="#genspider" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">genspider</span> <span class="pre">[-t</span> <span class="pre">template]</span> <span class="pre">&lt;name&gt;</span> <span class="pre">&lt;domain</span> <span class="pre">or</span> <span class="pre">URL&gt;</span></code></p></li>
<li><p>Requires project: <em>no</em></p></li>
</ul>
<div class="versionadded">
<p><span class="versionmodified added">New in version 2.6.0: </span>The ability to pass a URL instead of a domain.</p>
</div>
<p>Create a new spider in the current folder or in the current project’s <code class="docutils literal notranslate"><span class="pre">spiders</span></code> folder, if called from inside a project. The <code class="docutils literal notranslate"><span class="pre">&lt;name&gt;</span></code> parameter is set as the spider’s <code class="docutils literal notranslate"><span class="pre">name</span></code>, while <code class="docutils literal notranslate"><span class="pre">&lt;domain</span> <span class="pre">or</span> <span class="pre">URL&gt;</span></code> is used to generate the <code class="docutils literal notranslate"><span class="pre">allowed_domains</span></code> and <code class="docutils literal notranslate"><span class="pre">start_urls</span></code> spider’s attributes.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Even if an HTTPS URL is specified, the protocol used in
<code class="docutils literal notranslate"><span class="pre">start_urls</span></code> is always HTTP. This is a known issue: <a class="reference external" href="https://github.com/scrapy/scrapy/issues/3553">issue 3553</a>.</p>
</div>
<p>Usage example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$ scrapy genspider -l
Available templates:
  basic
  crawl
  csvfeed
  xmlfeed

$ scrapy genspider example example.com
Created spider &#39;example&#39; using template &#39;basic&#39;

$ scrapy genspider -t crawl scrapyorg scrapy.org
Created spider &#39;scrapyorg&#39; using template &#39;crawl&#39;
</pre></div>
</div>
<p>This is just a convenience shortcut command for creating spiders based on
pre-defined templates, but certainly not the only way to create spiders. You
can just create the spider source code files yourself, instead of using this
command.</p>
</section>
<section id="crawl">
<span id="std-command-crawl"></span><span id="std:command-crawl"></span><h3>crawl<a class="headerlink" href="#crawl" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">crawl</span> <span class="pre">&lt;spider&gt;</span></code></p></li>
<li><p>Requires project: <em>yes</em></p></li>
</ul>
<p>Start crawling using a spider.</p>
<p>Usage examples:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$ scrapy crawl myspider
[ ... myspider starts crawling ... ]
</pre></div>
</div>
</section>
<section id="check">
<span id="std-command-check"></span><span id="std:command-check"></span><h3>check<a class="headerlink" href="#check" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">check</span> <span class="pre">[-l]</span> <span class="pre">&lt;spider&gt;</span></code></p></li>
<li><p>Requires project: <em>yes</em></p></li>
</ul>
<p>Run contract checks.</p>
<p>Usage examples:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$ scrapy check -l
first_spider
  * parse
  * parse_item
second_spider
  * parse
  * parse_item

$ scrapy check
[FAILED] first_spider:parse_item
&gt;&gt;&gt; &#39;RetailPricex&#39; field is missing

[FAILED] first_spider:parse
&gt;&gt;&gt; Returned 92 requests, expected 0..4
</pre></div>
</div>
</section>
<section id="list">
<span id="std-command-list"></span><span id="std:command-list"></span><h3>list<a class="headerlink" href="#list" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">list</span></code></p></li>
<li><p>Requires project: <em>yes</em></p></li>
</ul>
<p>List all available spiders in the current project. The output is one spider per
line.</p>
<p>Usage example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$ scrapy list
spider1
spider2
</pre></div>
</div>
</section>
<section id="edit">
<span id="std-command-edit"></span><span id="std:command-edit"></span><h3>edit<a class="headerlink" href="#edit" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">edit</span> <span class="pre">&lt;spider&gt;</span></code></p></li>
<li><p>Requires project: <em>yes</em></p></li>
</ul>
<p>Edit the given spider using the editor defined in the <code class="docutils literal notranslate"><span class="pre">EDITOR</span></code> environment
variable or (if unset) the <a class="hoverxref tooltip reference internal" href="settings.html#std-setting-EDITOR"><code class="xref std std-setting docutils literal notranslate"><span class="pre">EDITOR</span></code></a> setting.</p>
<p>This command is provided only as a convenience shortcut for the most common
case, the developer is of course free to choose any tool or IDE to write and
debug spiders.</p>
<p>Usage example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$ scrapy edit spider1
</pre></div>
</div>
</section>
<section id="fetch">
<span id="std-command-fetch"></span><span id="std:command-fetch"></span><h3>fetch<a class="headerlink" href="#fetch" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">fetch</span> <span class="pre">&lt;url&gt;</span></code></p></li>
<li><p>Requires project: <em>no</em></p></li>
</ul>
<p>Downloads the given URL using the Scrapy downloader and writes the contents to
standard output.</p>
<p>The interesting thing about this command is that it fetches the page how the
spider would download it. For example, if the spider has a <code class="docutils literal notranslate"><span class="pre">USER_AGENT</span></code>
attribute which overrides the User Agent, it will use that one.</p>
<p>So this command can be used to “see” how your spider would fetch a certain page.</p>
<p>If used outside a project, no particular per-spider behaviour would be applied
and it will just use the default Scrapy downloader settings.</p>
<p>Supported options:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--spider=SPIDER</span></code>: bypass spider autodetection and force use of specific spider</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--headers</span></code>: print the response’s HTTP headers instead of the response’s body</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--no-redirect</span></code>: do not follow HTTP 3xx redirects (default is to follow them)</p></li>
</ul>
<p>Usage examples:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$ scrapy fetch --nolog http://www.example.com/some/page.html
[ ... html content here ... ]

$ scrapy fetch --nolog --headers http://www.example.com/
{&#39;Accept-Ranges&#39;: [&#39;bytes&#39;],
 &#39;Age&#39;: [&#39;1263   &#39;],
 &#39;Connection&#39;: [&#39;close     &#39;],
 &#39;Content-Length&#39;: [&#39;596&#39;],
 &#39;Content-Type&#39;: [&#39;text/html; charset=UTF-8&#39;],
 &#39;Date&#39;: [&#39;Wed, 18 Aug 2010 23:59:46 GMT&#39;],
 &#39;Etag&#39;: [&#39;&quot;573c1-254-48c9c87349680&quot;&#39;],
 &#39;Last-Modified&#39;: [&#39;Fri, 30 Jul 2010 15:30:18 GMT&#39;],
 &#39;Server&#39;: [&#39;Apache/2.2.3 (CentOS)&#39;]}
</pre></div>
</div>
</section>
<section id="view">
<span id="std-command-view"></span><span id="std:command-view"></span><h3>view<a class="headerlink" href="#view" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">view</span> <span class="pre">&lt;url&gt;</span></code></p></li>
<li><p>Requires project: <em>no</em></p></li>
</ul>
<p>Opens the given URL in a browser, as your Scrapy spider would “see” it.
Sometimes spiders see pages differently from regular users, so this can be used
to check what the spider “sees” and confirm it’s what you expect.</p>
<p>Supported options:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--spider=SPIDER</span></code>: bypass spider autodetection and force use of specific spider</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--no-redirect</span></code>: do not follow HTTP 3xx redirects (default is to follow them)</p></li>
</ul>
<p>Usage example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$ scrapy view http://www.example.com/some/page.html
[ ... browser starts ... ]
</pre></div>
</div>
</section>
<section id="shell">
<span id="std-command-shell"></span><span id="std:command-shell"></span><h3>shell<a class="headerlink" href="#shell" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">shell</span> <span class="pre">[url]</span></code></p></li>
<li><p>Requires project: <em>no</em></p></li>
</ul>
<p>Starts the Scrapy shell for the given URL (if given) or empty if no URL is
given. Also supports UNIX-style local file paths, either relative with
<code class="docutils literal notranslate"><span class="pre">./</span></code> or <code class="docutils literal notranslate"><span class="pre">../</span></code> prefixes or absolute file paths.
See <a class="hoverxref tooltip reference internal" href="shell.html#topics-shell"><span class="std std-ref">Scrapy shell</span></a> for more info.</p>
<p>Supported options:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--spider=SPIDER</span></code>: bypass spider autodetection and force use of specific spider</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-c</span> <span class="pre">code</span></code>: evaluate the code in the shell, print the result and exit</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--no-redirect</span></code>: do not follow HTTP 3xx redirects (default is to follow them);
this only affects the URL you may pass as argument on the command line;
once you are inside the shell, <code class="docutils literal notranslate"><span class="pre">fetch(url)</span></code> will still follow HTTP redirects by default.</p></li>
</ul>
<p>Usage example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$ scrapy shell http://www.example.com/some/page.html
[ ... scrapy shell starts ... ]

$ scrapy shell --nolog http://www.example.com/ -c &#39;(response.status, response.url)&#39;
(200, &#39;http://www.example.com/&#39;)

# shell follows HTTP redirects by default
$ scrapy shell --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c &#39;(response.status, response.url)&#39;
(200, &#39;http://example.com/&#39;)

# you can disable this with --no-redirect
# (only for the URL passed as command line argument)
$ scrapy shell --no-redirect --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c &#39;(response.status, response.url)&#39;
(302, &#39;http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F&#39;)
</pre></div>
</div>
</section>
<section id="parse">
<span id="std-command-parse"></span><span id="std:command-parse"></span><h3>parse<a class="headerlink" href="#parse" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">parse</span> <span class="pre">&lt;url&gt;</span> <span class="pre">[options]</span></code></p></li>
<li><p>Requires project: <em>yes</em></p></li>
</ul>
<p>Fetches the given URL and parses it with the spider that handles it, using the
method passed with the <code class="docutils literal notranslate"><span class="pre">--callback</span></code> option, or <code class="docutils literal notranslate"><span class="pre">parse</span></code> if not given.</p>
<p>Supported options:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">--spider=SPIDER</span></code>: bypass spider autodetection and force use of specific spider</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--a</span> <span class="pre">NAME=VALUE</span></code>: set spider argument (may be repeated)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--callback</span></code> or <code class="docutils literal notranslate"><span class="pre">-c</span></code>: spider method to use as callback for parsing the
response</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--meta</span></code> or <code class="docutils literal notranslate"><span class="pre">-m</span></code>: additional request meta that will be passed to the callback
request. This must be a valid json string. Example: –meta=’{“foo” : “bar”}’</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--cbkwargs</span></code>: additional keyword arguments that will be passed to the callback.
This must be a valid json string. Example: –cbkwargs=’{“foo” : “bar”}’</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--pipelines</span></code>: process items through pipelines</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--rules</span></code> or <code class="docutils literal notranslate"><span class="pre">-r</span></code>: use <a class="reference internal" href="spiders.html#scrapy.spiders.CrawlSpider" title="scrapy.spiders.CrawlSpider"><code class="xref py py-class docutils literal notranslate"><span class="pre">CrawlSpider</span></code></a>
rules to discover the callback (i.e. spider method) to use for parsing the
response</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--noitems</span></code>: don’t show scraped items</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--nolinks</span></code>: don’t show extracted links</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--nocolour</span></code>: avoid using pygments to colorize the output</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--depth</span></code> or <code class="docutils literal notranslate"><span class="pre">-d</span></code>: depth level for which the requests should be followed
recursively (default: 1)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--verbose</span></code> or <code class="docutils literal notranslate"><span class="pre">-v</span></code>: display information for each depth level</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--output</span></code> or <code class="docutils literal notranslate"><span class="pre">-o</span></code>: dump scraped items to a file</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 2.3.</span></p>
</div>
</li>
</ul>
<p>Usage example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$ scrapy parse http://www.example.com/ -c parse_item
[ ... scrapy log lines crawling example.com spider ... ]

&gt;&gt;&gt; STATUS DEPTH LEVEL 1 &lt;&lt;&lt;
# Scraped Items  ------------------------------------------------------------
[{&#39;name&#39;: &#39;Example item&#39;,
 &#39;category&#39;: &#39;Furniture&#39;,
 &#39;length&#39;: &#39;12 cm&#39;}]

# Requests  -----------------------------------------------------------------
[]
</pre></div>
</div>
</section>
<section id="settings">
<span id="std-command-settings"></span><span id="std:command-settings"></span><h3>settings<a class="headerlink" href="#settings" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">settings</span> <span class="pre">[options]</span></code></p></li>
<li><p>Requires project: <em>no</em></p></li>
</ul>
<p>Get the value of a Scrapy setting.</p>
<p>If used inside a project it’ll show the project setting value, otherwise it’ll
show the default Scrapy value for that setting.</p>
<p>Example usage:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$ scrapy settings --get BOT_NAME
scrapybot
$ scrapy settings --get DOWNLOAD_DELAY
0
</pre></div>
</div>
</section>
<section id="runspider">
<span id="std-command-runspider"></span><span id="std:command-runspider"></span><h3>runspider<a class="headerlink" href="#runspider" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">runspider</span> <span class="pre">&lt;spider_file.py&gt;</span></code></p></li>
<li><p>Requires project: <em>no</em></p></li>
</ul>
<p>Run a spider self-contained in a Python file, without having to create a
project.</p>
<p>Example usage:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$ scrapy runspider myspider.py
[ ... spider starts crawling ... ]
</pre></div>
</div>
</section>
<section id="version">
<span id="std-command-version"></span><span id="std:command-version"></span><h3>version<a class="headerlink" href="#version" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">version</span> <span class="pre">[-v]</span></code></p></li>
<li><p>Requires project: <em>no</em></p></li>
</ul>
<p>Prints the Scrapy version. If used with <code class="docutils literal notranslate"><span class="pre">-v</span></code> it also prints Python, Twisted
and Platform info, which is useful for bug reports.</p>
</section>
<section id="bench">
<span id="std-command-bench"></span><span id="std:command-bench"></span><h3>bench<a class="headerlink" href="#bench" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">bench</span></code></p></li>
<li><p>Requires project: <em>no</em></p></li>
</ul>
<p>Run a quick benchmark test. <a class="hoverxref tooltip reference internal" href="benchmarking.html#benchmarking"><span class="std std-ref">Benchmarking</span></a>.</p>
</section>
</section>
<section id="custom-project-commands">
<h2>Custom project commands<a class="headerlink" href="#custom-project-commands" title="Permalink to this headline">¶</a></h2>
<p>You can also add your custom project commands by using the
<a class="hoverxref tooltip reference internal" href="#std-setting-COMMANDS_MODULE"><code class="xref std std-setting docutils literal notranslate"><span class="pre">COMMANDS_MODULE</span></code></a> setting. See the Scrapy commands in
<a class="reference external" href="https://github.com/scrapy/scrapy/tree/master/scrapy/commands">scrapy/commands</a> for examples on how to implement your commands.</p>
<section id="commands-module">
<span id="std-setting-COMMANDS_MODULE"></span><span id="std:setting-COMMANDS_MODULE"></span><h3>COMMANDS_MODULE<a class="headerlink" href="#commands-module" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">''</span></code> (empty string)</p>
<p>A module to use for looking up custom Scrapy commands. This is used to add custom
commands for your Scrapy project.</p>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">COMMANDS_MODULE</span> <span class="o">=</span> <span class="s1">&#39;mybot.commands&#39;</span>
</pre></div>
</div>
</section>
<section id="register-commands-via-setup-py-entry-points">
<h3>Register commands via setup.py entry points<a class="headerlink" href="#register-commands-via-setup-py-entry-points" title="Permalink to this headline">¶</a></h3>
<p>You can also add Scrapy commands from an external library by adding a
<code class="docutils literal notranslate"><span class="pre">scrapy.commands</span></code> section in the entry points of the library <code class="docutils literal notranslate"><span class="pre">setup.py</span></code>
file.</p>
<p>The following example adds <code class="docutils literal notranslate"><span class="pre">my_command</span></code> command:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">setuptools</span> <span class="kn">import</span> <span class="n">setup</span><span class="p">,</span> <span class="n">find_packages</span>

<span class="n">setup</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;scrapy-mymodule&#39;</span><span class="p">,</span>
  <span class="n">entry_points</span><span class="o">=</span><span class="p">{</span>
    <span class="s1">&#39;scrapy.commands&#39;</span><span class="p">:</span> <span class="p">[</span>
      <span class="s1">&#39;my_command=my_scrapy_module.commands:MyCommand&#39;</span><span class="p">,</span>
    <span class="p">],</span>
  <span class="p">},</span>
 <span class="p">)</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../intro/examples.html" class="btn btn-neutral float-left" title="Examples" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="spiders.html" class="btn btn-neutral float-right" title="Spiders" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2008–2022, Scrapy developers.
      <span class="commit">Revision <code>23537a0f</code>.
      </span>
      <span class="lastupdated">Last updated on May 26, 2022.
      </span></p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="Versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: latest
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      <dl>
        <dt>Versions</dt>
        
          <dd><a href="/en/master/">master</a></dd>
        
          <dd><a href="/en/latest/">latest</a></dd>
        
          <dd><a href="/en/stable/">stable</a></dd>
        
          <dd><a href="/en/2.6/">2.6</a></dd>
        
          <dd><a href="/en/2.5/">2.5</a></dd>
        
          <dd><a href="/en/2.4/">2.4</a></dd>
        
          <dd><a href="/en/2.3/">2.3</a></dd>
        
          <dd><a href="/en/2.2/">2.2</a></dd>
        
          <dd><a href="/en/2.1/">2.1</a></dd>
        
          <dd><a href="/en/2.0/">2.0</a></dd>
        
          <dd><a href="/en/1.8/">1.8</a></dd>
        
          <dd><a href="/en/1.7/">1.7</a></dd>
        
          <dd><a href="/en/1.6/">1.6</a></dd>
        
          <dd><a href="/en/1.5/">1.5</a></dd>
        
          <dd><a href="/en/1.4/">1.4</a></dd>
        
          <dd><a href="/en/1.3/">1.3</a></dd>
        
          <dd><a href="/en/1.2/">1.2</a></dd>
        
          <dd><a href="/en/1.1/">1.1</a></dd>
        
          <dd><a href="/en/1.0/">1.0</a></dd>
        
          <dd><a href="/en/0.24/">0.24</a></dd>
        
          <dd><a href="/en/0.22/">0.22</a></dd>
        
          <dd><a href="/en/0.20/">0.20</a></dd>
        
          <dd><a href="/en/0.18/">0.18</a></dd>
        
          <dd><a href="/en/0.16/">0.16</a></dd>
        
          <dd><a href="/en/0.14/">0.14</a></dd>
        
          <dd><a href="/en/0.12/">0.12</a></dd>
        
          <dd><a href="/en/0.10.3/">0.10.3</a></dd>
        
          <dd><a href="/en/0.9/">0.9</a></dd>
        
          <dd><a href="/en/xpath-tutorial/">xpath-tutorial</a></dd>
        
      </dl>
      <dl>
        <dt>Downloads</dt>
        
          <dd><a href="//docs.scrapy.org/_/downloads/en/latest/pdf/">pdf</a></dd>
        
          <dd><a href="//docs.scrapy.org/_/downloads/en/latest/htmlzip/">html</a></dd>
        
          <dd><a href="//docs.scrapy.org/_/downloads/en/latest/epub/">epub</a></dd>
        
      </dl>
      <dl>
        
        <dt>On Read the Docs</dt>
          <dd>
            <a href="//readthedocs.org/projects/scrapy/?fromdocs=scrapy">Project Home</a>
          </dd>
          <dd>
            <a href="//readthedocs.org/builds/scrapy/?fromdocs=scrapy">Builds</a>
          </dd>
      </dl>
    </div>
  </div>
<script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script type="text/javascript">
analytics.ready(function () {
    ga('require', 'linker');
    ga('linker:autoLink', ['zyte.com']);
});
</script>


</body>
</html>